<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Rails | Staal Forge]]></title>
  <link href="http://staal.io/blog/categories/rails/atom.xml" rel="self"/>
  <link href="http://staal.io/"/>
  <updated>2013-02-13T15:18:33+07:00</updated>
  <id>http://staal.io/</id>
  <author>
    <name><![CDATA[Boris Staal]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Dangers of Turbolinks]]></title>
    <link href="http://staal.io/blog/2013/01/18/dangers-of-turbolinks/"/>
    <updated>2013-01-18T21:35:00+07:00</updated>
    <id>http://staal.io/blog/2013/01/18/dangers-of-turbolinks</id>
    <content type="html"><![CDATA[<p>Turbolinks! This "award-winning" technology earned incredible amount of criticism in such a short time! But it still is on the roadmap of Rails 4. As an evangelist of client frameworks I did not find any interest in that previously. And now suddenly life has brought us together. So let's see if it really is THAT bad. And what are the reasons if it is.</p>

<h3>Part 1. Well-known problems</h3>

<h4>Document ready event</h4>

<p>Problems don't keep waiting. <a href="http://railscasts.com/episodes/390-turbolinks">RailsCast #390</a> starts the marathon with the most popular issue: Turbolinks do not call document's <code>ready</code> event.</p>

<p><code>coffeescript
$ -&gt; alert '123'
</code></p>

<p>This code runs only during direct page loads. Turbolinks fetcher ignores it.</p>

<!-- more -->


<p>It has pretty simple workaround that is already wrapped into a tiny gem called <a href="https://github.com/kossnocorp/jquery.turbolinks">jquery-turbolinks</a>. It solves this problem for the particular jQuery framework (and same can be done same way for any other). Okay. This solution looks transparent. But is it?</p>

<h4>Global scope does not get cleaned</h4>

<p>Turbolinks clames it reduces load time due to the fact browser doesn't have to reevaluate your assets. True. But not only assets remain. The whole global scope saves a state.</p>

<p>Imagine we have a page with the script from previous example. Script is injected into the <code>body</code> tag. It could be i.e. some kind of external service inclusion. What happens in this case? It adds one more binding per each load. It evaluates one time for the first page, two times for second and so on. Bindings do not disappear automaticaly like before. You suddenly appear in a locked environment where nobody but you is responsible for page desctruction routines.</p>

<p>There is one sad but real rule: frontend developers do not write idempotent code. They never care.</p>

<h3>Part 2. Going deeper</h3>

<h4>Global scope does not get cleaned 2</h4>

<p>The worst side-effect of this behavior however is not in bindings. They are easily catchable in particular case of <code>ready</code> event. Let's see what happens if we have heavy backbone application instead that <code>alert</code> script. Backbone applications are likely to use <code>window</code> as a global namespace to store reachable instances.</p>

<p>We have 2 pages <strong>A</strong> and <strong>B</strong>. <strong>A</strong> is the text-only welcome page. <strong>B</strong> is the page that bootstraps backbone applicaton and therefore links it to particular DOM node. Backbone has:</p>

<ul>
<li>4 structured views</li>
<li>1 collection</li>
<li>1 model</li>
</ul>


<p>The collection gets cached to <code>window</code> namespace to be shared between views:</p>

<p><code>coffeescript
collection: -&gt; window.AppView.currentCollection ||= new AppCollection
</code></p>

<p>So we load page <strong>B</strong>. Backbone bootstraps, creates the collection and works seamlesly. Until you go to page <strong>A</strong> and back. What happens in this case? We get <em>new</em> Backbone app. And the <em>old</em> collection. With the state it was left at.</p>

<p>Then things go worse. Imagine it was not a collection that was stored this way. Imagine it was a model or view. And they had bindings to DOM events. As you might forecast – they remain alive. But not the DOM they were binded to. Another point of failure.</p>

<h4>Intervals and Timeouts</h4>

<p>Global page scope includes a lot of different entities you might never think of. Another two popular functions that can raise issues are <code>setInterval</code> and <code>setTimeout</code>. The problem is mostly the same – whenever you reload a page, timers disappear. But not with Turbolinks. All the intervals will live forever until you stop them manually. Try starting your interval inside a particular page and watch their number growing. Welcome to time ghetto buddy!</p>

<h3>Part 3. Something you might not even think about</h3>

<p>I've started studying Turbolinks from reviews. So actually when I got to it's source I was already aware of the described issues. The reason was simple – as an author of browser framework I already faced them at Joosy. And had to solve each of them at the framework level. But there's one thing at sources that shocked me like a lightning bolt.</p>

<p><strong>Turbolinks store DOM trees of last 10 loaded pages.</strong></p>

<p>Javascript does not have a way to directly erase an object once it was created. Engine automatically destroys all instances that are not referenced from anywhere. There are two things that make it awkward:</p>

<ul>
<li>It's Javascript. Oppa-lambda-style.</li>
<li>Nobody ever cares</li>
</ul>


<p>It's incredibly easy to drain all the RAM out of client with a large application. But it's affordable and, well, we can live with that since all that stuff is dead as soon as we reload a page. But thanks to Turbolinks it's no more!</p>

<p>Let me explain. Your large JS application is likely to be a huge graph that's INCREDIBLY linked. It's very typical for a JS app to have mostly atomic unload. In theory even with Turbolinks, as soon as we drop the page out and load the next one we are supposed to detach the application. Dereferenced application gets collected and our RAM is free again! But Turbolinks save DOM. And DOM has bindings. And bindings reference you application. So big parts of your application survive at page reload. Therefore in practice there's a HUGE chance that Turbolinks will boost RAM usage up to 10 times.</p>

<p>But... It's not the worst again! Turbolinks don't just store 10 last pages. They are stored for a reason. As soon as you go back – it restores your DOM. Therefore restoring your application parts. Now your application is likely to be broken – remember your botstrap has already been exectued several time for next pages. But some of bindings remain alive. How do you even debug that for god sake?</p>

<h3>What do you need it for?</h3>

<p>Most of critics additionaly claim Turbolinks is pretty useless. It's up to you to decide: <a href="https://github.com/steveklabnik/turbolinks_test">https://github.com/steveklabnik/turbolinks_test</a>.</p>

<p>There is however small advantage that Turbolinks could give you – the ability to controll page switch animation. Unfortunately it doesn't have required hooks. If you need animation – you should go use full-stack browser framework.</p>

<h3>Turbolinks is the silent killer</h3>

<p>Turbolinks claim that it's the successor to pjax that seamlessly works out of box. As you can see – it's not even close to that. Real problems of Turbolinks are hidden deep inside. Existing MVC frameworks like Ember or Joosy address such problems – they may use different approaches but they face them. Turbolinks silently ignore it. And if it will ever try start fighting – it will turn into another MVC framework.</p>

<p>Remember: with Turbolinks you might easily fix surface issues. But it's an iceberg so think twice. You have to write your code in a very special way to work with that. You are likely to have issues with legacy code. And you get almost nothing for that.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redistributable Rails applications]]></title>
    <link href="http://staal.io/blog/2013/01/12/redistributable-rails-applications/"/>
    <updated>2013-01-12T22:48:00+07:00</updated>
    <id>http://staal.io/blog/2013/01/12/redistributable-rails-applications</id>
    <content type="html"><![CDATA[<p>Imagine you have a large Rails application that you are going to distribute. That's might be a new world-crashing CMS or incredibly modern Redmine fork. Every separate installation produced by a consumer requires different configs. Or maybe even some code that will adapt your product for particular needs using amazing internal API.</p>

<p>Clever consumer will also want to store such a "deployment" in his own git repository. And as the last point – he will definitely require a nice way to maintain ability to upgrade your product within required version branch.</p>

<p><strong>How do you achieve that?</strong></p>

<p>Let me share my story first. I manage two banking products: Roundbank and Smartkiosk. They are Rails applications. Every time bank wants to deploy Roundbank-based internet banking I need a way to:</p>

<ol>
<li>Get my core and create a nice new look that will match bank's design using internal API.</li>
<li>Extend core with the transport methods that are required to integrate with bank's core banking platform.</li>
<li>Support it.</li>
</ol>


<p>First two steps are pretty easy. It can even be a fork on the Github. And then comes third. Release management crashes. Especially if bank has own team that's involved. Another downside of forks is that your consumer has the whole codebase inside his project. You might not think so but... damn! So provocative! You remember he's not supposed to change anything right?</p>

<!-- more -->


<h3>Gems</h3>

<p>The solution to the dependency management is wide-known – Ruby Gems. Gems have nice versioning system that will solve the issue. You have a Rails application – can it be a gem at the same time? Answer is yes.</p>

<p>I wrote <a href="http://github.com/inossidabile/matrioshka/tree/master/lib/generators/matrioshka/templates">a tiny gem called Matrioshka</a>. It contains the set of generators that will make everything on your behalf. Following sections will describe it's internals. You can skip it safely to the end of the article to read about gem itself.</p>

<p>So what exactly do we need to allow another Rails application include the whole application as a gem?</p>

<h5>1. gemspec, init.rb</h5>

<p>Every gem starts with a gemspec and initialization routines. You will need the following files: <code>$application.gemspec</code>, <code>lib/$application.rb</code> and <code>init.rb</code>. Here is what Roundbank contains (patched a bit :):</p>

<p>```ruby
lib = File.expand_path('../lib', <strong>FILE</strong>)
$LOAD_PATH.unshift(lib) unless $LOAD_PATH.include?(lib)
require 'roundbank'</p>

<p>Gem::Specification.new do |gem|
  gem.name          = 'roundbank'
  gem.version       = Roundbank::VERSION
  gem.authors       = ['']
  gem.email         = ['']
  gem.description   = %q{Write a gem description}
  gem.summary       = %q{Write a gem summary}
  gem.homepage      = ''
  gem.files         = <code>git ls-files</code>.split($/)</p>

<p>  gem.executables   = gem.files.grep(%r{<sup>bin/}).map{</sup> |f| File.basename(f) }
  gem.test_files    = gem.files.grep(%r{<sup>(test|spec|features)/})</sup>
  gem.require_paths = ['lib']
end
```</p>

<p><code>ruby
module Roundbank
  VERSION = '0.0.1'
end
</code></p>

<p><code>ruby
require 'roundbank'
</code></p>

<h5>2. Models/Controllers</h5>

<p>Rails has out-of-box solution called Rails Engines. All you have to do is to extend your <code>lib/$application.rb</code> a bit.</p>

<p>```ruby
require 'rails/engine'</p>

<p>module Roundbank
  VERSION = '0.0.1'</p>

<p>  class Engine &lt; ::Rails::Engine
  end
end
```</p>

<p>Rails Engines system was created to make Rails applications extendible by gems. But it's abilities are underestimated. It will even run <code>config/initializers</code> and <code>config/environments</code> for you. In fact it will transparently include most of your project with just the following code.</p>

<h5>3. I18n, autoload_path, migrations</h5>

<p>Mot of your project. Excluding some options. We need to help it a bit with a clever initializer.</p>

<p>```ruby
require 'rails/engine'</p>

<p>module Roundbank
  VERSION = '0.0.1'</p>

<p>  class Engine &lt; ::Rails::Engine</p>

<pre><code>initializer 'matrioshka', :before =&gt; :set_autoload_paths do |app|
  app.class.configure do
    config.i18n.load_path += Dir[Roundbank::Engine.root.join(*%w(config locales *.{rb,yml})).to_s]
    config.autoload_paths += %W(#{Roundbank::Engine.root.join 'lib'})
    config.paths['db/migrate'] += Roundbank::Engine.paths['db/migrate'].existent
  end
end
</code></pre>

<p>  end
end
```</p>

<p>This will proxy your locales, autoloadable pathes and even migrations! Note that there is popular approach to copy migrations from gems. Two words: NO WAY. Described initializer will allow you to seamlessly run migrations from both sources. They will stay ordered.</p>

<h5>4. Seeds</h5>

<p>Seeds are not handled by Rails Engines too. And moreover you can't improve your situation from within your gem. However all you need to do is to extend <code>db/seeds.rb</code> of descendant project with the following line:</p>

<p><code>ruby
load Roundbank::Engine.root.join(*%w(db seeds.rb))
</code></p>

<h5>5. Gemfile</h5>

<p>This is the worst part. Ruby Gems are great. However some parts of it do not hold water.</p>

<p><strong>You can not use gems from git</strong></p>

<p>Okay it might be a strange requirement. But did you never use it with the Bundler itself? It's extremely comfortable and useful. Are you ready to abandon it? I am not.</p>

<p><strong>You can not split gems for platforms</strong></p>

<p>Roundbank can work under MRI and JRuby. And it uses slightly different set of gems for different platforms. What am I supposed to do with that? There are some workarounds that invoke proper dependencies of a particular platform from within compilation hooks – don't even try those. They will not work with Bundler well. They will stay ignored for <code>:path =&gt;</code> inclusion and even <code>:git =&gt;</code> inclusion. The worst thing is that new Ruby Gems 2.0 are ought to be released. And still no progress.</p>

<p>The best option I was able to come up with is to copy host project <code>Gemfile</code> to every descendant project. Put it to, say, <code>Gemfile.roundbank</code> and then require:</p>

<p><code>ruby
eval_gemfile 'Gemfile.roundbank'
</code></p>

<h5>6. Transparent initialization</h5>

<p>During initial startup Rails relies on <code>Foo::Application</code> constant heavily. You might <code>grep</code> you code for that – it's everywhere. Rack setup, Environments, Initializers, .... But now that we are trying to run it in a very special way – it will fail. <code>Foo::Application</code> will not exist in inherited context. Instead of that we are supposed to configure the descendant.</p>

<p>And here comes magic. During class initialization at <code>config/application.rb</code> your application instance is storead at <code>Rails.application</code> property. The final step required to make your application gem-compatible is to replace <code>Foo::Applicaton</code> with <code>Rails.application.class</code> everywhere. Here is the total list of locations you should check:</p>

<p><code>
config.ru
Rakefile
config/environment.rb
config/routes.rb
config/environments/development.rb
config/environments/production.rb
config/environments/test.rb
config/initializers/secret_token.rb
config/initializers/session_store.rb
</code></p>

<p>This replacement makes the code application-indepent. No matter what application runs it – it always uses proper instances.</p>

<h5>Summary</h5>

<p>As soon as these 6 steps are done – you can pack your new gem and use it from any other Rails application. At the same time host application will remain runable from itself also.</p>

<p>But why do all that steps manually if <a href="https://github.com/inossidabile/matrioshka/">Matrioshka</a> can do that for you?</p>

<h3>Matrioshka</h3>

<p>I tested this approach at Roundbank and fell in love. To extend it to other products and automate the 5th step I created the Matrioshka gem. It will do everything for you with it's mighty generators.</p>

<h5>Host Application (Gem)</h5>

<p>Inject the following to your host application Gemfile:</p>

<p><code>ruby
gem 'matrioshka'
</code></p>

<p>Run Matrioshka install generator</p>

<p><code>bash
rails g matrioshka:install
</code></p>

<p>It will generate all the required additions and patches. For a typical application they will just work. However you probably should edit <code>$application.gemspec</code> to set proper meta information for your future gem.</p>

<h5>Client Application (Consumer)</h5>

<p>As soon as your gem is ready to rumble we can procceed to the consumer. Let's make it work within a new rails application:</p>

<p><code>bash
rails new marakash
</code></p>

<p>Add your application gem to the new Gemfile:</p>

<p><code>ruby
gem '$application'
</code></p>

<p>Run <code>bundle install</code> and then</p>

<p><code>bash
rake $application:link
</code></p>

<p>Ta-dam. You are done here. Time to party hard!</p>

<p>Love.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rails acceptance tests coverage]]></title>
    <link href="http://staal.io/blog/2012/11/24/rails-acceptance-tests-coverage/"/>
    <updated>2012-11-24T23:52:00+07:00</updated>
    <id>http://staal.io/blog/2012/11/24/rails-acceptance-tests-coverage</id>
    <content type="html"><![CDATA[<p>Most of our banking products share the same architecture. We use Rails as a REST application server and <a href="http://www.joosy.ws">Joosy</a> application working at browser as a client. One of the greatest advantages we get is the ability to cover the whole Ruby implementation with the acceptance tests. We use <strong>requests</strong> specs that are <a href="https://github.com/rspec/rspec-rails#request-specs">part of RSpec Rails</a> integration. However it’s easier said then done: our remote banking app-server for instance has near 500 routes to test. And the number of active routes grows constantly.</p>

<p>Managing such a great amount of routes is a real pain no matter how good you organize your specs. To solve that my colleague <a href="http://twitter.com/ImGearHead">Andrew</a> prepared a small rspec plugin handling exactly this task: counting what’s tested on your behalf.  We spent several days playing with it and increasing it’s functionality. Join us and have some fun with the <a href="https://github.com/inossidabile/rspec-routes_coverage">rspec-routes_coverage</a> gem.</p>

<h3>Usage</h3>

<p>Plugin will add the following stats to your basic RSpec output:</p>

<p><img src="http://f.cl.ly/items/3F0G0l1J250j0a392m1O/rspec.png" alt="" /></p>

<!-- more -->


<p>First line is for the total number of routes you consider “actual”. By default gem will harvest all the routes your application possess. As soon as you don’t want to test some of them you can use the following code to improve the situation:</p>

<p>```ruby
RSpec.configure do |config|
  config.routes_coverage.exclude_namespaces = %w(back)
  config.routes_coverage.exclude_routes = [</p>

<pre><code>/^\/$/,
/^POST \/sessions/
</code></pre>

<p>  ]
end
```</p>

<p>Second line is for the number of “manually-marked-as-tested” routes. At first sight it may seem that as soon as your route got a request it can be considered tested. But sometimes it’s not. To give you some control over the situation plugin introduces the <code>describe_request</code> helper. Use it instead of RSpec’s <code>describe</code> passing in the route you want to mark as checked. Here is the tiny sample:</p>

<p>```ruby
require 'spec_helper'</p>

<p>describe ItemsController do</p>

<p>  describe_request :index, request_path: '/items', method: 'GET' do</p>

<pre><code>it 'lists items' do
  get '/items'
  # ...
end
</code></pre>

<p>  end</p>

<p>  # another style:
  describe_request 'GET /items/:id' do</p>

<pre><code>it 'shows item' do
  get "/items/#{Item.first.id}"
  # ...
end
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>The third line contains the counter of routes that received at least one HTTP request.</p>

<p>And the final line shows you the amount of routes that were not tested in any way. So get ‘em and test ‘em!</p>

<h3>Verbosity</h3>

<p>The default output (see the screenshot) will appear at any RSpec call to provide the basic summary. However you definitely require the ability to list routes of each category. To go deeper use the <code>LIST_ROUTES_COVERAGE=true</code> option. Also you can use the Rake helper that we prepared for you:</p>

<p><code>sh
rake spec:requests:coverage
</code></p>

<h3>Workflow</h3>

<p>The resulting workflow could look the following way:</p>

<ul>
<li>Include Gem</li>
<li>Exclude useless routes</li>
<li>Write tests using list of pending routes to cover it all</li>
<li>Wrap your tests into describe_request blocks to mark specs as manually checked</li>
<li>Start “green acceptance” party</li>
</ul>


<p>Enjoy! :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Joosy: alternative approach to browser frameworks]]></title>
    <link href="http://staal.io/blog/2012/06/04/joosy-alternative-approach-to-browser-frameworks/"/>
    <updated>2012-06-04T23:42:00+07:00</updated>
    <id>http://staal.io/blog/2012/06/04/joosy-alternative-approach-to-browser-frameworks</id>
    <content type="html"><![CDATA[<h3>Long story short</h3>

<p>We created a new JS framework that doesn’t clone anything existing but uses slightly different approach. Joosy we call it.</p>

<ul>
<li><a href="http://www.joosy.ws">Joosy website</a></li>
<li><a href="http://guides.joosy.ws/guides/basics/getting-started.html">Getting started guide</a></li>
<li><a href="https://github.com/joosy/joosy">Github Repo</a></li>
</ul>


<h3>Real introduction</h3>

<p>Ourdays even a lazy and his grandmother is doing his own JS MVC framework. The reason is simple: we really need it. The problem, on the other side, is that everyone is just cloning Backbone. There is also Knockout and Ember that went a different way. Still not enough to satisfy sophisticated audience. The problems are different. Some may dislike Handlebars. The others won’t fit general API. It’s a matter of taste after all. The options are always good if you choose between something different.</p>

<!-- more -->


<p>Half of year ago during some of new projects we started a tiny experiment. We took generally another approach to this problem: to consider JS Framework an extension to your backend. It should not be abstracted but exactly the opposite: binded to the server side as tightly as possible. It should replace your backend’s view layer. And be the View, just a View. What you usually call “model” is just a data set binded to the template. And JS logic is simply an extension to the template that makes it sophisticated but doesn’t make it a standalone application. We used Rails as a backend.</p>

<p>To make it real we had to implement all the common things Rails people are used to and properly extend them with the abilities that Rails lack. Better organization of code, new conventions for statefull environment and so on. With that we’ve reproduced forms, helpers and even the HAML everything working right in your browser.</p>

<p>Now that the time has passed and some of that projects are in production, we are ready to release this experiment as a mature feature-rich framework. Called “<a href="http://www.joosy.ws/">Joosy</a>”.</p>

<p>Joosy is based on View terms. Pages, Layouts, Helpers and templates. Inside, it uses <a href="http://coffeescript.org">CoffeScript</a> possibilities massively. To make Coffee better, Joosy includes awesome <a href="http://sugarjs.com">Sugar.JS</a> library that feels like ActiveSupport. So you have better language that is sweetened.</p>

<p>Joosy has everything you are used to within another frameworks but with slightly another sause. It has routing, “models” with identity map, nice structure and much more. Like ActiveSupport, ActiveResource-compatible interface, background generators, preloaders, etc.</p>

<p>The practice shown: it’s very easy to jump in if you are used to Rails. It either does what other claims to do: it definitely saves your time. So no matter if you need this or not, please read through “<a href="http://guides.joosy.ws/guides/basics/getting-started.html">Getting Started</a>” guide. At least we have something new to offer and it won’t be dull. And then, maybe, you’ll find a great use for it :).</p>

<p>Feel free to ask any questions at Stack Overflow using <code>joosy</code> tag. I will be there :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Heimdallr: ORM field-level security]]></title>
    <link href="http://staal.io/blog/2012/04/01/heimdallr-orm-field-level-security/"/>
    <updated>2012-04-01T23:02:00+07:00</updated>
    <id>http://staal.io/blog/2012/04/01/heimdallr-orm-field-level-security</id>
    <content type="html"><![CDATA[<p>We are currently migrating most of our products to browser-side application. One of the worst issues it raises is proper permissions handling. There are no comfortable ways to implement context-based protection of models (and their fields) within ActiveRecord (Egor, say hi ;). <code>attr_acessible</code> is too weak. CanCan is too abstract (doesn't go down to fields).</p>

<p>We’ve figured out something awesome to solve this issue. Meet <a href="https://github.com/roundlake/heimdallr/">Heimdallr</a> and it’s extension <a href="https://github.com/roundlake/heimdallr-resource">Heimdallr::Resource</a>. They will bring you a peace and security.</p>

<h3>Heimdallr</h3>

<p>Let’s start from the deeper problem investigation though. Large part of Rails projects equates security to a REST restriction. The bigger projects sometimes fall down to a model to keep code DRY. And to keep your controllers/actions number from getting wild you may fall down to fields.</p>

<p><img src="http://media.tumblr.com/tumblr_m1tdm3wF8m1r9yc7i.png" alt="" /></p>

<!-- more -->


<p>For properly designed RESTful applications, 1st and 2nd levels are same. So we are left with:</p>

<ol>
<li>Entity access level</li>
<li>Entity fields separate restrictions</li>
</ol>


<p>Field-level management gets more and more important while your application grows. And Github’s discreditation is a great example of what you can get if you go “fields? Who cares?..” way.</p>

<p>To take a long story short, here’s what <code>Heimdallr</code> allows to define inside a model:</p>

<p>```ruby
class Article &lt; ActiveRecord::Base
  include Heimdallr::Model</p>

<p>  belongs_to :owner, :class_name => 'User'</p>

<p>  restrict do |user, record|</p>

<pre><code>if user.admin?
  # Administrator or owner can do everything
  scope :fetch
  scope :delete
  can [:view, :create, :update]
else
  # Other users can view only their own or non-classified articles...
  scope :fetch,  -&gt; { where('owner_id = ? or secrecy_level &lt; ?', user.id, 5) }
  scope :delete, -&gt; { where('owner_id = ?', user.id) }

  # ... and see all fields except the actual security level
  # (through owners can see everything)...
  if record.try(:owner) == user
    can :view
    can :update, {
      secrecy_level: { inclusion: { in: 0..4 } }
    }
  else
    can    :view
    cannot :view, [:secrecy_level]
  end

  # ... and can create them with certain restrictions.
  can :create, %w(content)
  can :create, {
    owner_id:      user.id,
    secrecy_level: { inclusion: { in: 0..4 } }
  }
end
</code></pre>

<p>  end
end
```</p>

<p>Using straightforward DSL inside your models you define both, model and field-level restrictions. <code>Heimdallr</code> will extend all required models with <code>.restrict</code> method. It will wrap your model class into the Proxy that can be used in a default manner.</p>

<p><code>ruby
Article.restrict(current_user).where(:typical =&gt; true)
</code></p>

<p>Note that an entity (second) parameter is not always available during evaluation. Therefore <strong>all the checks depending on inner fields state should be wrapped with</strong> <code>.try(:field)</code>.</p>

<p>These restrictions can be used anywhere in your project. Not only in your controllers. And that’s damn important. If you try to get anything that is protected – you get an exception. This makes the behavior predictable. But it’s so uncomfortable for the views!</p>

<p>To avoid this <code>Heimdallr</code> has two restriction strategies. By default it will follow the first one, explicit strategy that raises an exception. However this is how you can switch:</p>

<p>```ruby
article = Article.restrict(current_user).first
article.protected_thing # exception!</p>

<p>@article = article.implicit
@article.protected_thing # => nil
```</p>

<h3>CanCan</h3>

<p>For the most Rails projects the Security term is often an alias for the CanCan gem. While CanCan was really an epoch and it still is superb it has some problems:</p>

<ul>
<li>CanCan was designed to interfere with models as least as possible. It proposes architecture where you get your REST implementation protected but models are plain and unrestricted. By itself this plan is sometimes good and sometimes not. The fact is that it can not get to fields whatever you do.</li>
<li>1.x branch is dead and unsupported. It has some awful bugs for complex cases with namespaces and 2.x takes so much time to appear.</li>
</ul>


<p>We’ve started <code>Heimdallr</code> as a tool to maintain security on a model level but it appeared that we have enough info to restrict controller among our DSL. So it took just a few moment to come up with <code>Heimdallr::Resource</code>.</p>

<p>The resource part of <code>Heimdallr</code> mimics CanCan as much as possible. You still get your <code>load_and_authorize filter</code> and this is how it works:</p>

<ul>
<li>If you don’t have your :create scope defined (and therefore can not create any entity) you are considered to not be able to request new and create.</li>
<li>If you don’t have your :update scope, you can not request edit and update.</li>
<li>Same goes for :destroy scope.</li>
<li>Inside your actions you get protected entities so you can’t forget explicit restrict call.</li>
</ul>


<p>Here is the example:</p>

<p>```ruby
class ArticlesController &lt; ApplicationController
  include Heimdallr::Resource</p>

<p>  load_and_authorize_resource</p>

<p>  # or set the name explicitly:
  #
  # load_and_authorize_resource :resource => :article</p>

<p>  # if nested:
  #
  # routes.rb:
  #   resources :categories do
  #     resources :articles
  #   end
  #
  # load_and_authorize_resource :through => :category</p>

<p>  def index</p>

<pre><code># @articles is loaded and restricted here
</code></pre>

<p>  end</p>

<p>  def create</p>

<pre><code># @article is loaded and restricted here
</code></pre>

<p>  end
end
```</p>

<h3>REST API Providers</h3>

<p>I’ve started my narrative from the roots of these gems, the restriction sync between client applications and server-side REST-based APIs. Let me tell you a bit about conventions we came up with.</p>

<p>Imagine you have simple role-based CRUD interface that you want to implement on a browser side. You have index/create/update/destroy REST endpoint. Restrictions give us following questions:</p>

<ul>
<li>Which entities am I able to get through index?</li>
<li>Which entities of those are modifiable?</li>
<li>Which entities of those are destroyable?</li>
<li>Am I able to create a new entity?</li>
<li>Which fields am I able to modify for one of those entities I’m able to edit?</li>
<li>Which fields am I able to fill while creating a new entity if I’m able to?</li>
</ul>


<p>The first question is already addressed by <code>Heimdallr</code> itself. You get your scope and you simply can’t get anything besides what you are allowed to.</p>

<p>To get further with 2nd and 3d we should use meta-magic provided by <code>Heimdallr</code> proxy:</p>

<p><code>ruby
{modifiable: @model.modifiable?, destroyable: @model.destroyable?}
</code></p>

<p><code>@model</code> is supposed to be resricted. Add this fields to your serialization and you know the capabilities of current user.</p>

<h4>Am I able to create? And which fields?</h4>

<p><code>new</code> method is a rare guest among REST APIs. And it’s a perfect place to determine if we are able to create entity and how exactly. Here is the code to list fields we can modify:</p>

<p><code>ruby
Article.restrictions(current_user).allowed_fields[:create]
</code></p>

<p>Within <code>Heimdallr::Resource</code> you’ll get restriction error if you can not create it at all. <code>Heimdallr</code> either defines <code>.creatable?</code> method so you can pass it on too.</p>

<h4>Which fields am I able to update</h4>

<p>The idea behind modification is quite the same. Just use <code>edit</code> method and <code>:update</code> keyword to retrieve fields that are accessible.</p>

<p><code>ruby
Article.restrictions(current_user).allowed_fields[:update]
</code></p>

<h3>Summary</h3>

<p>Using <code>Heimdallr</code> and <code>Heimdallr::Resource</code> you can get your application protected quite well with no boilerplate. And what’s not really hot: you get amazing magic for your REST APIs. So use it and be happy. Remember, Homakov is <a href="http://homakov.blogspot.com/2012/03/egor-stop-hacking-gh.html">watching you</a>!</p>

<p>ಠ_ಠ</p>
]]></content>
  </entry>
  
</feed>
